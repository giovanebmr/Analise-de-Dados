{"cells":[{"cell_type":"code","source":["\n# Path - dataset1\npath_dataset1 = \"/FileStore/tables/country_vaccinations.csv\"\n \n# Path - RDD\npath_rdd = \"/FileStore/tables/arquivo_rdd.txt\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed82620f-fbf9-468a-8e99-25ae7ed36bef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Leitura de Dataframe\n \n## Opção 1\ndf1 = spark.read.format(\"csv\").option(\"header\",\"true\").load(path_dataset1)\n \n## Opção 2\ndf1 = spark.read.csv(path_dataset1)\ndf1 = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(path_dataset1)\n \n## Exibindo dataframe\ndf1.show(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"652092c5-3e29-4088-b375-dc6843ffaa7b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------+------------------+--------------------+\n|  country|iso_code|      date|total_vaccinations|people_vaccinated|people_fully_vaccinated|daily_vaccinations_raw|daily_vaccinations|total_vaccinations_per_hundred|people_vaccinated_per_hundred|people_fully_vaccinated_per_hundred|daily_vaccinations_per_million| vaccines|       source_name|      source_website|\n+---------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------+------------------+--------------------+\n|Argentina|     ARG|2020-12-29|             700.0|             null|                   null|                  null|              null|                           0.0|                         null|                               null|                          null|Sputnik V|Ministry of Health|http://datos.salu...|\n|Argentina|     ARG|2020-12-30|              null|             null|                   null|                  null|           15656.0|                          null|                         null|                               null|                         346.0|Sputnik V|Ministry of Health|http://datos.salu...|\n+---------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------+------------------+--------------------+\nonly showing top 2 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------+------------------+--------------------+\n  country|iso_code|      date|total_vaccinations|people_vaccinated|people_fully_vaccinated|daily_vaccinations_raw|daily_vaccinations|total_vaccinations_per_hundred|people_vaccinated_per_hundred|people_fully_vaccinated_per_hundred|daily_vaccinations_per_million| vaccines|       source_name|      source_website|\n+---------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------+------------------+--------------------+\nArgentina|     ARG|2020-12-29|             700.0|             null|                   null|                  null|              null|                           0.0|                         null|                               null|                          null|Sputnik V|Ministry of Health|http://datos.salu...|\nArgentina|     ARG|2020-12-30|              null|             null|                   null|                  null|           15656.0|                          null|                         null|                               null|                         346.0|Sputnik V|Ministry of Health|http://datos.salu...|\n+---------+--------+----------+------------------+-----------------+-----------------------+----------------------+------------------+------------------------------+-----------------------------+-----------------------------------+------------------------------+---------+------------------+--------------------+\nonly showing top 2 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["## Outras formas de leitura de arquivos com PySpark\n \npath = \"/../../arquivoXPTO\"\n \n# Criando um dataframe a partir de um JSON\ndataframe = spark.read.json(path)\n \n# Criando um dataframe a partir de um ORC\ndataframe = spark.read.orc(path)\n \n# Criando um dataframe a partir de um PARQUET\ndataframe = spark.read.parquet(path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"faa97d9a-f039-4d61-8a56-1931ea3fcb8f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["## Outras formas de leitura de arquivos com PySpark\n \npath = \"/../../arquivoXPTO\"\n \n# Criando um dataframe a partir de um JSON\ndataframe = spark.read.json(path)\n \n# Criando um dataframe a partir de um ORC\ndataframe = spark.read.orc(path)\n \n# Criando um dataframe a partir de um PARQUET\ndataframe = spark.read.parquet(path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ed7844a-a266-4afe-b04b-d692f8ae2763"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Leitura de um RDD\n \nrdd = sc.textFile(path_rdd)\n#rdd.show() = Errado, não é possível exibir um SHOW() de um RDD, somente um Dataframe\nrdd.collect()\nOut[24]: ['XXXXXcerveja8.99XXXbohemialata',\n 'refrigerante6.50XXcocacolalata',\n 'XXXXXXXXaguaXX20bonafontegalao']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0bf27154-00ca-4a85-8fa2-12cdf738de55"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Criando uma tabela temporária\nnome_tabela_temporiaria = \"tempTableDataFrame1\"\ndf1.createOrReplaceTempView(nome_tabela_temporiaria)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21c5f9ff-986c-4abc-8466-9853ecb055c2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Lendo a tabela temporaria opcao 1\nspark.read.table(nome_tabela_temporiaria).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc3a1dca-9047-4924-9a4f-fbb2e1f289ca"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"SELECT * FROM tempTableDataFrame1\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e76bd0b-a423-4655-a42e-4c255c509829"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Visualização do Databricks\ndisplay(spark.sql(\"SELECT * FROM tempTableDataFrame1\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d9c7d7e3-9f53-4d00-8d58-ef368d078b37"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Scala\n#import org.apache.spark.sql.functions._\n \n# Python\nfrom pyspark.sql.functions import col, column\n \n# Usando function col ou column\ndf1.select(col(\"country\"), col(\"date\"), column(\"iso_code\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79eca7ba-f539-41b8-9c7e-cc16d8cbf5c7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["df1.selectExpr(\"country\", \"date\", \"iso_code\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"693e79b2-0f6e-4d20-acce-2428ec885582"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Scala import\n# org.apache.spark.sql.types._\n \n# Criando um Schema manualmente no PySpark\nfrom pyspark.sql.types import *\n \ndataframe_ficticio = StructType([\n                      StructField(\"col_String_1\", StringType()),\n                      StructField(\"col_Integer_2\", IntegerType()),\n                      StructField(\"col_Decimal_3\", DecimalType())\n                              ])\ndataframe_ficticio\nOut[2]: StructType(List(StructField(col_String_1,StringType,true),StructField(col_Integer_2,IntegerType,true),StructField(col_Decimal_3,DecimalType(10,0),true)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5423839d-ac4e-46c4-9eb7-d3906627c94c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Função para gerar Schema (campos/colunas/nomes de colunas)\n \n'''\n# Scala\n \norg.apache.spark.sql.types._\n \ndef getSchema(fields : Array[StructField]) : StructType = {\n  new StructType(fields)\n}\n'''\n \n# PySpark\ndef getSchema(fields):\n  return StructType(fields)\n  \nschema = getSchema([StructField(\"coluna1\", StringType()), StructField(\"coluna2\", StringType()), StructField(\"coluna3\", StringType())])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c17c112a-fb60-48a9-9e25-e6110b33068a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["schema\nOut[4]: StructType(List(StructField(coluna1,StringType,true),StructField(coluna2,StringType,true),StructField(coluna3,StringType,true)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"448b7c8e-4ee4-43fb-b901-911c404dcfc7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Gravando um novo CSV\n \npath_destino=\"/FileStore/tables/CSV/\"\nnome_arquivo=\"arquivo.csv\"\npath_geral= path_destino + nome_arquivo\ndf1.write.format(\"csv\").mode(\"overwrite\").option(\"sep\", \"\\t\").save(path_geral)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91dfec94-ecfc-4b0b-874c-5eff79da8edf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Gravando um novo JSON\n \npath_destino=\"/FileStore/tables/JSON/\"\nnome_arquivo=\"arquivo.json\"\npath_geral= path_destino + nome_arquivo\ndf1.write.format(\"json\").mode(\"overwrite\").save(path_geral)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b214ea97-cbdb-41e6-8e6d-835640ef9258"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Gravando um novo PARQUET\n \npath_destino=\"/FileStore/tables/PARQUET/\"\nnome_arquivo=\"arquivo.parquet\"\npath_geral= path_destino + nome_arquivo\ndf1.write.format(\"parquet\").mode(\"overwrite\").save(path_geral)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b52bcda-f821-46b1-a1a6-03e8c06540bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Gravando um novo ORC\n \npath_destino=\"/FileStore/tables/ORC/\"\nnome_arquivo=\"arquivo.orc\"\npath_geral= path_destino + nome_arquivo\ndf1.write.format(\"orc\").mode(\"overwrite\").save(path_geral)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"196592ab-793d-472f-a802-336c93bb5fad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Outros tipos de SELECT\n \n#Diferentes formas de selecionar uma coluna\n \nfrom pyspark.sql.functions import *\n \ndf1.select(\"country\").show(5)\ndf1.select('country').show(5)\ndf1.select(col(\"country\")).show(5)\ndf1.select(column(\"country\")).show(5)\ndf1.select(expr(\"country\")).show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5edb6219-a46b-4fd5-bb01-febbbd9011dc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Define uma nova coluna com um valor constante\ndf2 = df1.withColumn(\"nova_coluna\", lit(1))\n \n# Adicionar coluna\nteste = expr(\"total_vaccinations < 40\")\ndf1.select(\"country\", \"total_vaccinations\").withColumn(\"teste\", teste).show(5)\n \n# Renomear uma coluna\ndf1.select(expr(\"total_vaccinations as total_de_vacinados\")).show(5)\ndf1.select(col(\"country\").alias(\"pais\")).show(5)\ndf1.select(\"country\").withColumnRenamed(\"country\", \"pais\").show(5)\n \n# Remover uma coluna\ndf3 = df1.drop(\"country\")\ndf3.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3368a776-448e-40a1-9729-6ca3454134f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Filtrando dados e ordenando\n# where() é um alias para filter().\n \n# Seleciona apenas os primeiros registros da coluna \"total_vaccinations\"\ndf1.filter(df1.total_vaccinations > 55).orderBy(df1.total_vaccinations).show(2)\n \n# Filtra por país igual Argentina\ndf1.select(df1.total_vaccinations, df1.country).filter(df1.country == \"Argentina\").show(5)\n \n# Filtra por país diferente Argentina\ndf1.select(df1.total_vaccinations, df1.country).where(df1.country != \"Argentina\").show(5) # python type\n \n# Mostra valores únicos\ndf1.select(\"country\").distinct().show()\n \n# Especificando vários filtros em comando separados\nfiltro_vacinas = df1.total_vaccinations < 100\nfiltro_pais = df1.country.contains(\"Argentina\")\ndf1.select(df1.total_vaccinations, df1.country, df1.vaccines).where(df1.vaccines.isin(\"Sputnik V\", \"Sinovac\")).filter(filtro_vacinas).show(5)\ndf1.select(df1.total_vaccinations, df1.country, df1.vaccines).where(df1.vaccines.isin(\"Sputnik V\", \"Sinovac\")).filter(filtro_vacinas).withColumn(\"filtro_pais\", filtro_pais).show(5)\n "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2b55ad2-b039-4156-bd7d-9aedb02f7056"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["\"\"\"#######################################################################################################################\nConvertendo dados\n#######################################################################################################################\"\"\"\n \ndf5 = df1.withColumn(\"PAIS\", col(\"country\").cast(\"string\").alias(\"PAIS\"))\ndf5.select(df5.PAIS).show(2)\n \n\"\"\"#######################################################################################################################\nTrabalhando com funções\n#######################################################################################################################\"\"\"\n \n# Usando funções\ndf1.select(upper(df1.country)).show(3)\ndf1.select(lower(df1.country)).show(4)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c3d3ef4-c3a6-4a76-b41a-7cbc3237b69b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Criando um dataframe genérico\n \nd = [{'name': 'Alice', 'age': 1}]\ndf_A = spark.createDataFrame(d)\ndf_A.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e2e0c24-892e-413b-bbd0-6150f03679c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["rdd1 = [{\"nome\": \"Marco\",\"idade\": 33,\"status\": 'true'},\n{\"nome\": \"Antonio\",\"idade\":33,\"status\": 'true'},\n{\"nome\":\"Pereira\",\"idade\":33,\"status\": 'true'},\n{\"nome\":\"Helena\",\"idade\":30,\"status\": 'true'},\n{\"nome\":\"Fernando\",\"idade\":35,\"status\": 'true'},\n{\"nome\":\"Carlos\",\"idade\":28,\"status\": 'true'},\n{\"nome\":\"Lisa\",\"idade\":26,\"status\": 'true'},\n{\"nome\":\"Candido\",\"idade\":75,\"status\": 'false'},\n{\"nome\":\"Vasco\",\"idade\":62,\"status\": 'true'}\n]\ndff1 = spark.createDataFrame(rdd1)\ndff1.show()\n \n \nrdd2 = [\n{\"nome\":\"Marco\",\"PaisOrigem\":\"Brasil\"},\n{\"nome\":\"Helena\",\"PaisOrigem\":\"Brasil\"},\n{\"nome\":\"Gabriel\",\"PaisOrigem\":\"Brasil\"},\n{\"nome\":\"Vasco\",\"PaisOrigem\":\"Portugal\"},\n{\"nome\":\"Medhi\",\"PaisOrigem\":\"Marocco\"}]\n \ndff2 = spark.createDataFrame(rdd2)\ndff2.show()\n \n'''\njoin_type = \"inner\"\n \n+------+-----+------+------+----------+\n|  nome|idade|status|  nome|PaisOrigem|\n+------+-----+------+------+----------+\n| Vasco|   62|  true| Vasco|  Portugal|\n| Marco|   33|  true| Marco|    Brasil|\n|Helena|   30|  true|Helena|    Brasil|\n+------+-----+------+------+----------+\n'''\n \n'''val join_type = \"left_semi\"\n \n+------+-----+------+\n|  nome|idade|status|\n+------+-----+------+\n| Vasco|   62|  true|\n| Marco|   33|  true|\n|Helena|   30|  true|\n+------+-----+------+\n'''\n \n'''val join_type = \"right_outer\"\n \n+------+-----+------+-------+----------+\n|  nome|idade|status|   nome|PaisOrigem|\n+------+-----+------+-------+----------+\n| Vasco|   62|  true|  Vasco|  Portugal|\n| Marco|   33|  true|  Marco|    Brasil|\n|  null| null|  null|Gabriel|    Brasil|\n|Helena|   30|  true| Helena|    Brasil|\n|  null| null|  null|  Medhi|   Marocco|\n+------+-----+------+-------+----------+\n'''\n \n'''val join_type = \"left_outer\"\n \n+--------+-----+------+------+----------+\n|    nome|idade|status|  nome|PaisOrigem|\n+--------+-----+------+------+----------+\n| Antonio|   33|  true|  null|      null|\n|   Vasco|   62|  true| Vasco|  Portugal|\n|   Marco|   33|  true| Marco|    Brasil|\n| Pereira|   33|  true|  null|      null|\n|  Carlos|   28|  true|  null|      null|\n|Fernando|   35|  true|  null|      null|\n| Candido|   75| false|  null|      null|\n|  Helena|   30|  true|Helena|    Brasil|\n|    Lisa|   26|  true|  null|      null|\n+--------+-----+------+------+----------+\n'''\n \n'''join_type = \"full_outer\"\n \n+--------+-----+------+-------+----------+\n|    nome|idade|status|   nome|PaisOrigem|\n+--------+-----+------+-------+----------+\n| Antonio|   33|  true|   null|      null|\n|   Vasco|   62|  true|  Vasco|  Portugal|\n|   Marco|   33|  true|  Marco|    Brasil|\n| Pereira|   33|  true|   null|      null|\n|  Carlos|   28|  true|   null|      null|\n|    null| null|  null|Gabriel|    Brasil|\n|Fernando|   35|  true|   null|      null|\n| Candido|   75| false|   null|      null|\n|  Helena|   30|  true| Helena|    Brasil|\n|    Lisa|   26|  true|   null|      null|\n|    null| null|  null|  Medhi|   Marocco|\n+--------+-----+------+-------+----------+\n'''\n \n'''join_type = \"left_anti\"\n \n+--------+-----+------+\n|    nome|idade|status|\n+--------+-----+------+\n| Antonio|   33|  true|\n| Pereira|   33|  true|\n|  Carlos|   28|  true|\n|Fernando|   35|  true|\n| Candido|   75| false|\n|    Lisa|   26|  true|\n+--------+-----+------+\n'''\n \njoin_type = \"left_anti\"\njoin_condition = dff1.nome == dff2.nome\ndf3 = dff1.join(dff2, join_condition, join_type)\ndf3.show()\n \n#df1.groupBy(\"status\").agg(countDistinct(col(\"idade\"))).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9e54c07-0bab-41ee-a221-5d37445dfd73"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/session.py:387: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n  warnings.warn(&#34;inferring schema from dict is deprecated,&#34;\n+-----+--------+------+\n|idade|    nome|status|\n+-----+--------+------+\n|   33|   Marco|  true|\n|   33| Antonio|  true|\n|   33| Pereira|  true|\n|   30|  Helena|  true|\n|   35|Fernando|  true|\n|   28|  Carlos|  true|\n|   26|    Lisa|  true|\n|   75| Candido| false|\n|   62|   Vasco|  true|\n+-----+--------+------+\n\n+----------+-------+\n|PaisOrigem|   nome|\n+----------+-------+\n|    Brasil|  Marco|\n|    Brasil| Helena|\n|    Brasil|Gabriel|\n|  Portugal|  Vasco|\n|   Marocco|  Medhi|\n+----------+-------+\n\n+-----+--------+------+\n|idade|    nome|status|\n+-----+--------+------+\n|   33| Antonio|  true|\n|   75| Candido| false|\n|   28|  Carlos|  true|\n|   35|Fernando|  true|\n|   26|    Lisa|  true|\n|   33| Pereira|  true|\n+-----+--------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/session.py:387: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n  warnings.warn(&#34;inferring schema from dict is deprecated,&#34;\n+-----+--------+------+\nidade|    nome|status|\n+-----+--------+------+\n   33|   Marco|  true|\n   33| Antonio|  true|\n   33| Pereira|  true|\n   30|  Helena|  true|\n   35|Fernando|  true|\n   28|  Carlos|  true|\n   26|    Lisa|  true|\n   75| Candido| false|\n   62|   Vasco|  true|\n+-----+--------+------+\n\n+----------+-------+\nPaisOrigem|   nome|\n+----------+-------+\n    Brasil|  Marco|\n    Brasil| Helena|\n    Brasil|Gabriel|\n  Portugal|  Vasco|\n   Marocco|  Medhi|\n+----------+-------+\n\n+-----+--------+------+\nidade|    nome|status|\n+-----+--------+------+\n   33| Antonio|  true|\n   75| Candido| false|\n   28|  Carlos|  true|\n   35|Fernando|  true|\n   26|    Lisa|  true|\n   33| Pereira|  true|\n+-----+--------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["join_type = \"left_anti\"\njoin_condition = dff1.nome == dff2.nome\ndf3 = dff1.join(dff2, join_condition, join_type)\ndf3.show()\n \n#df1.groupBy(\"status\").agg(countDistinct(col(\"idade\"))).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffa9e74e-abd9-42b7-a80f-757f4759b323"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+--------+------+\n|idade|    nome|status|\n+-----+--------+------+\n|   33| Antonio|  true|\n|   75| Candido| false|\n|   28|  Carlos|  true|\n|   35|Fernando|  true|\n|   26|    Lisa|  true|\n|   33| Pereira|  true|\n+-----+--------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------+------+\nidade|    nome|status|\n+-----+--------+------+\n   33| Antonio|  true|\n   75| Candido| false|\n   28|  Carlos|  true|\n   35|Fernando|  true|\n   26|    Lisa|  true|\n   33| Pereira|  true|\n+-----+--------+------+\n\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"covid","dashboards":[],"language":"python","widgets":{},"notebookOrigID":759424698903284}},"nbformat":4,"nbformat_minor":0}
